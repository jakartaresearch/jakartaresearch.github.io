---
layout: post
title: Data Jam EP 3 - Multimodal Deep Learning
---

## Overview
Multimodal deep learning is an approach in machine learning that focuses on processing and understanding data from **multiple modalities or sources**, such as **text**, **images**, **audio**, and more. This approach aims to leverage the complementary information provided by these different data types to improve the accuracy and richness of machine learning models --by gpt

- GitHub - [pliang279/awesome-multimodal-ml: Reading list for research topics in multimodal machine learning](https://github.com/pliang279/awesome-multimodal-ml)
- [MML Tutorial - Schedule](https://cmu-multicomp-lab.github.io/mmml-tutorial/schedule/)
- [CLIP: Connecting text and images](https://openai.com/research/clip)
- [Contrastive Learning - Papers With Code](https://paperswithcode.com/task/contrastive-learning#:~:text=Contrastive%20Learning%20is%20a%20deep,dissimilar%20instances%20are%20far%20apart)
